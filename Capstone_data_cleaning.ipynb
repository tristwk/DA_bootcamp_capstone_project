{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "# change setting - to show all the columns \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "listings = pd.read_csv(\"/Users/tristakuo/neuefische/capstone-project/data/listings.csv.gz\")\n",
    "\n",
    "# subset: listing \n",
    "listing = listings[['id','name', 'description','neighborhood_overview', 'neighbourhood_group_cleansed', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', 'minimum_minimum_nights', 'minimum_maximum_nights',   \n",
    "'availability_365','host_id','host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'number_of_reviews','number_of_reviews_ltm', 'first_review','last_review', 'review_scores_rating', 'review_scores_accuracy','review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'license', 'instant_bookable', 'calculated_host_listings_count','reviews_per_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many null values in each columns\n",
    "listing.isna().sum()\n",
    "\n",
    "# null value investigation summary:  \n",
    "# description is the first part of the intro - does not affect our analysis if null\n",
    "# neighborhood_overview is located at the lower part of the page \"where you will be\" - does not affect our analysis if null\n",
    "# 18 bathrooms_text is null cuz the host did not explicitly choose to show it - can be manually checked \n",
    "# bedrooms is null if the host did not explicitly choose it - 121 out of 1370 has a keyword \"studio\" in the \"description\" (can be 0 bedrooms? if not specified)\n",
    "# 339 beds are null \n",
    "# 8393 host response time/rate are null and 7405 host acceptance rate are null - info hidden \n",
    "# 10 hosts hid info on superhost (double checked with the data where host_id > 2, confirmed these 10 only have 1 listing) - can assign values to listings_count  & total_listing\n",
    "# 2883 listings have 0 reviews (first_review, last_review, review_scores_rating are null)\n",
    "# when the review was generated automatically due to a cancellation by the host, counted as 1 review without details on accuracy, communication etc.    \n",
    "# giving values to all category isn't mandatory for the guests - we see inconsistent null values across all categories \n",
    "# 11433 hosts do not reveal their registration info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further narrow down the dataframe \n",
    "\n",
    "listing_property = listing[['id','name', 'description','neighborhood_overview', 'neighbourhood_group_cleansed', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms_text','bedrooms', 'beds', 'amenities', 'price', 'minimum_minimum_nights', 'minimum_maximum_nights',   \n",
    "'availability_365','host_id','review_scores_rating']]\n",
    "\n",
    "# check null values\n",
    "listing_property.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change neighbourhood_group_cleansed column name\n",
    "listing_property.rename(columns= {'neighbourhood_group_cleansed':'neighborhood'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data types\n",
    "\n",
    "# id \n",
    "listing_property['id'] = listing_property['id'].astype(object)\n",
    "\n",
    "# price in remove $ sign, remove \".\" \n",
    "listing_property['price'] = listing_property['price'].str.replace('$','')\n",
    "listing_property['price'] = listing_property['price'].str.replace('.', '')\n",
    "listing_property['price'] = listing_property['price'].str.replace(',', '')\n",
    "listing_property['price'] = listing_property['price'].astype(float)\n",
    "\n",
    "# clean price / 100 \n",
    "listing_property['price'] = listing_property['price']/100 \n",
    "\n",
    "# host_id\n",
    "listing_property['host_id'] = listing_property['host_id'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicates - no duplicates!\n",
    "\n",
    "listing_property.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers checks\n",
    "  \n",
    "listing_property.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop price = 0\n",
    "listing_property =  listing_property.drop(listing[listing['price'] == 0].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values for 'bathrooms_text', 'bedrooms', 'beds'\n",
    "listing_property.dropna(axis= 0, how= 'any', subset= ['bathrooms_text', 'bedrooms', 'beds'], inplace= True)\n",
    "listing_property.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check null values\n",
    "listing_property.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check categorical data \n",
    "listing_property['neighborhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['room_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['accommodates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['bathrooms_text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['bedrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['beds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column for bathroom type\n",
    "# return 1/2 in a new column if bathrooms are shared  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['bathrooms_text'] = listing_property['bathrooms_text'].astype(str)\n",
    "listing_property['bathrooms_text'] = listing_property['bathrooms_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['share_bath'] = listing_property['bathrooms_text'].apply(lambda x: np.select([x.__contains__('shared')], '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_property['share_bath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store dataframes for other ipynbs\n",
    "%store listing\n",
    "%store listing_property\n",
    "%store calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tables to the database\n",
    "# import packages\n",
    "import sql_functions as sf\n",
    "import sqlalchemy \n",
    "from sql_functions import get_sql_config\n",
    "from sql_functions import get_engine\n",
    "import psycopg2\n",
    "\n",
    "sql_config = get_sql_config()\n",
    "engine = get_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload listing\n",
    "\n",
    "table_name = 'listing'\n",
    "schema = 'capstone_tk' \n",
    "\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        listing.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload listing_property\n",
    "\n",
    "table_name = 'listing_property'\n",
    "schema = 'capstone_tk' \n",
    "\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        listing_property.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload calendar\n",
    "\n",
    "table_name = 'calendar'\n",
    "schema = 'capstone_tk' \n",
    "\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        calendar.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r listing_property_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload listing_property_t\n",
    "\n",
    "table_name = 'listing_property_t'\n",
    "schema = 'capstone_tk' \n",
    "\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        listing_property_t.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nf_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab3d85a18739f6fff6a9c8c504adc2ff9340867b576dede986e2ee74c099e4e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
